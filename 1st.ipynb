{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG4s9iJ7uJIqARO/V5+JiA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC9mDqCv601g"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Install and Import Required Libraries\n",
        "!pip install transformers datasets evaluate torch --quiet\n",
        "!pip install gradio --quiet\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "# STEP 2: Load Dataset (AG News from Hugging Face)\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "print(dataset)\n",
        "\n",
        "# STEP 3: Tokenize Dataset (for BERT input)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names\n",
        "\n",
        "# STEP 4: Load Pretrained BERT Model for Classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
        "\n",
        "# STEP 5: Prepare Data for Training\n",
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "test_dataset = tokenized_datasets[\"test\"]\n",
        "\n",
        "metric_acc = evaluate.load(\"accuracy\")\n",
        "metric_f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1\": metric_f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
        "    }\n",
        "# STEP 6: Training Arguments & Trainer\n",
        "!pip install --upgrade transformers --quiet  # Run this at the start once\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",   # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",         # Save model after each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# STEP 7: Train the Model\n",
        "trainer.train()\n",
        "\n",
        "# STEP 8: Evaluate Model Performance\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", results)\n",
        "\n",
        "# STEP 9: Deploy Simple Gradio Interface\n",
        "labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "def predict_news(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    preds = torch.softmax(outputs.logits, dim=1)\n",
        "    return {labels[i]: float(preds[0][i]) for i in range(len(labels))}\n",
        "\n",
        "interface = gr.Interface(fn=predict_news, inputs=\"text\", outputs=\"label\", title=\"News Topic Classifier (BERT)\")\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPbeZVyR65j3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}